{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuGGwjf/yI2wtzztSM3BoY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cleitonrib/Cleitonrib/blob/main/Projeto_Imers%C3%A3o_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip -q install google-genai"
      ],
      "metadata": {
        "id": "T22e5MAlqcAC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zsIqwnDodNFl"
      },
      "outputs": [],
      "source": [
        "# Configura o cliente da SDK do Gemini\n",
        "\n",
        "from google import genai\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "9fOLSusAqGSG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "2el4GOHSsVLs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json  # Para salvar/carregar o histórico e progresso (opcional)\n",
        "\n",
        "# --- Configurações ---\n",
        "genai.configure(api_key=\"AIzaSyBqGRYruizDS01pldwlU0jAqIcZpC4Z0ek\")\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "# --- Funções de Apoio ---\n",
        "\n",
        "def carregar_historico(nome_aluno=\"\"):\n",
        "    try:\n",
        "        with open(f\"historico_{nome_aluno}.json\", \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return []\n",
        "\n",
        "def salvar_historico(historico, nome_aluno=\"\"):\n",
        "    with open(f\"historico_{nome_aluno}.json\", \"w\") as f:\n",
        "        json.dump(historico, f)\n",
        "\n",
        "def carregar_progresso(nome_aluno=\"\"):\n",
        "    try:\n",
        "        with open(f\"progresso_{nome_aluno}.json\", \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return {\"pontuacao\": 0, \"topicos_concluidos\": []}\n",
        "\n",
        "def salvar_progresso(progresso, nome_aluno=\"\"):\n",
        "    with open(f\"progresso_{nome_aluno}.json\", \"w\") as f:\n",
        "        json.dump(progresso, f)\n",
        "\n",
        "def gerar_prompt(pergunta, nome_aluno=\"\", historico=None, atividade_atual=None, resposta_aluno=None):\n",
        "    prompt_base = f\"\"\"\n",
        "Você é um tutor de Língua Portuguesa para alunos do Ensino Fundamental (adaptando-se ao nível do aluno).\n",
        "Mantenha um tom amigável e encorajador. Utilize exemplos relevantes e explique de forma clara.\n",
        "\n",
        "Histórico da conversa (se disponível):\n",
        "{historico if historico else \"Nenhum histórico ainda.\"}\n",
        "\n",
        "{'Atividade anterior:' + atividade_atual if atividade_atual else ''}\n",
        "{'Resposta do aluno:' + resposta_aluno if resposta_aluno else ''}\n",
        "\n",
        "Instruções específicas (se aplicável):\n",
        "- Se o aluno fez uma pergunta, responda de forma clara e concisa.\n",
        "- Se uma atividade foi proposta e o aluno respondeu, avalie a resposta e forneça feedback.\n",
        "- Periodicamente, proponha diferentes tipos de atividades (quiz de múltipla escolha, verdadeiro/falso, corrija a frase, complete a lacuna) para verificar a compreensão.\n",
        "\n",
        "Aluno: {nome_aluno}: {pergunta if not atividade_atual else 'Resposta'}\n",
        "Tutor: Olá, {nome_aluno}!\n",
        "\"\"\"\n",
        "    return prompt_base\n",
        "\n",
        "def perguntar_ao_tutor_gemini(prompt):\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Desculpe, houve um erro ao conectar com o tutor de IA (Gemini): {e}\"\n",
        "\n",
        "# --- Lógica Principal ---\n",
        "\n",
        "print(\"PortuguÊnio (Gemini Sofisticado): Tutor de Português\\nDigite 'sair' para encerrar.\")\n",
        "\n",
        "nome_aluno = input(\"Professor PortuguÊnio: Olá! Qual o seu nome?\\nAluno: \")\n",
        "# nivel_aluno = input(f\"Professor PortuguÊnio: Em qual nível você está (ex: básico, intermediário, avançado), {nome_aluno}?\\nAluno: \") # Opcional\n",
        "\n",
        "historico_conversa = carregar_historico(nome_aluno)\n",
        "progresso_aluno = carregar_progresso(nome_aluno)\n",
        "\n",
        "atividade_atual = None\n",
        "resposta_aluno_atividade = None\n",
        "\n",
        "while True:\n",
        "    if not atividade_atual:\n",
        "        pergunta_aluno = input(f\"{nome_aluno}: \")\n",
        "        if pergunta_aluno.lower() == 'sair':\n",
        "            salvar_historico(historico_conversa, nome_aluno)\n",
        "            salvar_progresso(progresso_aluno, nome_aluno)\n",
        "            break\n",
        "\n",
        "        prompt = gerar_prompt(pergunta_aluno, nome_aluno, historico_conversa)\n",
        "        resposta_ia = perguntar_ao_tutor_gemini(prompt)\n",
        "        print(f\"Professor PortuguÊnio: {resposta_ia}\\n\")\n",
        "        historico_conversa.append(f\"Aluno: {pergunta_aluno}\")\n",
        "        historico_conversa.append(f\"Tutor: {resposta_ia}\")\n",
        "\n",
        "        # Lógica para identificar se a IA propôs uma atividade (precisa ser mais estruturada)\n",
        "        if \"quiz:\" in resposta_ia.lower() or \"corrija a frase:\" in resposta_ia.lower() or \"complete a lacuna:\" in resposta_ia.lower():\n",
        "            atividade_atual = resposta_ia\n",
        "            resposta_aluno_atividade = None # Reset para a nova atividade\n",
        "    else:\n",
        "        resposta_aluno_atividade = input(f\"{nome_aluno} (Resposta): \")\n",
        "        prompt_verificacao = gerar_prompt(resposta_aluno_atividade, nome_aluno, historico_conversa, atividade_atual, resposta_aluno_atividade)\n",
        "        resposta_verificacao_ia = perguntar_ao_tutor_gemini(prompt_verificacao)\n",
        "        print(f\"Professor PortuguÊnio (Verificação): {resposta_verificacao_ia}\\n\")\n",
        "        historico_conversa.append(f\"Aluno (Resposta): {resposta_aluno_atividade}\")\n",
        "        historico_conversa.append(f\"Tutor (Verificação): {resposta_verificacao_ia}\")\n",
        "        # Lógica para atualizar o progresso (pontuação, tópicos) com base na resposta_verificacao_ia\n",
        "        atividade_atual = None\n",
        "        resposta_aluno_atividade = None\n",
        "\n",
        "    # Limitar o histórico para não ficar muito longo (opcional)\n",
        "    if len(historico_conversa) > 20:\n",
        "        historico_conversa = historico_conversa[-20:]\n",
        "\n",
        "print(f\"Obrigado por aprender com o PortuguÊnio, {nome_aluno}!\")\n",
        "print(f\"Seu progresso: Pontuação - {progresso_aluno['pontuacao']}, Tópicos Concluídos - {progresso_aluno['topicos_concluidos']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fqFPUJGs7DT",
        "outputId": "1411134c-8b0a-46d5-9003-f05da955d918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PortuguÊnio (Gemini Sofisticado): Tutor de Português\n",
            "Digite 'sair' para encerrar.\n"
          ]
        }
      ]
    }
  ]
}